{
  "id": "851623a4-5402-4207-beec-1bd51f5e641b",
  "data": {
    "nodes": [
      {
        "id": "ChatInput-jyJxK",
        "type": "genericNode",
        "position": {
          "x": 1320.8706644301817,
          "y": 1166.7934791719817
        },
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-jyJxK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "What is the average engagement rate for each platform?"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "ChatInput"
        },
        "selected": false,
        "width": 320,
        "height": 233
      },
      {
        "id": "Prompt-waFGY",
        "type": "genericNode",
        "position": {
          "x": 1659.4306090904684,
          "y": 692.2297099846659
        },
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-waFGY",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are an analytics model, specialized in analyzing social media data for a specific account. Your task is to process, understand, and generate insights from the provided DataStax {dataset}. \n\nData Analysis Tasks:\n1.\tAnalyze engagement metrics (likes, comments, shares) and trends over time.\n2.\tIdentify key performance indicators (KPIs) such as follower growth, post reach, and engagement rates.\n3.\tDetect patterns or anomalies in user interactions and content performance.\n4.\tProvide sentiment analysis of comments and feedback.\n5.\tGenerate reports on content effectiveness, audience demographics, and optimal posting times.\n6.\tForecast future trends or engagement based on historical data.\n\nUser Interaction Guidelines:\n•\tAccurately interpret user {request}.\n•\tPresent data insights clearly and concisely, tailored to social media metrics.\n•\tOffer explanations, summaries, or recommendations based on the data.\n•\tProvide visual aids or charts for complex data insights if needed.\n\nOutput Requirements:\n•\tEnsure clarity and relevance in your responses.\n•\tFormat insights in a user-friendly manner, emphasizing key takeaways.\n•\tInclude actionable recommendations to improve social media performance.\n\nExample User Queries and Outputs:\n•Query 1: What are the engagement trends for the past month?\nOutput: \"In the past month, the overall engagement increased by 15%. The posts on Wednesdays and Fridays saw the highest engagement, averaging 20% more interactions compared to other days. Peak engagement times were between 12 PM and 3 PM. Video content generated 30% higher engagement than image posts, with a notable spike in comments and shares. The most engaged post was 'Post A,' which received 1,200 likes, 300 comments, and 150 shares.\"\n\n•\tQuery 2: Which posts had the highest engagement in the last quarter?\nOutput: \"During the last quarter, the top three posts by engagement were:\n    Post A (June 15th): 2,500 likes, 400 comments, 250 shares.\n    Post B (July 10th): 2,200 likes, 350 comments, 200 shares.\n    Post C (August 5th): 1,800 likes, 300 comments, 180 shares. These posts featured engaging visuals and interactive content, contributing to higher user interaction.\"\n\n•\tQuery 3: Analyze the sentiment of user comments for our latest campaign.\nOutput: \"The sentiment analysis of comments from the latest campaign shows a positive trend. Out of 1,500 comments:\n    Positive Sentiment: 65% (users praised the product and campaign visuals).\n    Neutral Sentiment: 25% (general feedback or inquiries).\n    Negative Sentiment: 10% (concerns about product availability and pricing). Overall, the campaign was well-received, with a strong emphasis on user satisfaction.\"\n\n•\tQuery 4: Identify the optimal time to post for maximum reach.\nOutput: \"Analysis of the past six months reveals that the optimal posting times for maximum reach are:\n\n    Weekdays: 12 PM to 2 PM\n    Weekends: 10 AM to 1 PM Posts during these times consistently achieved 25% higher reach and engagement. The data suggests scheduling content around these hours can significantly boost visibility.\"\n\n•\tQuery 5: How has follower growth changed over the past year?\nOutput: \"Over the past year, follower growth has increased by 40%, with significant spikes during the following periods:\n    January to March: A 15% growth driven by the 'New Year Campaign.'\n    June to August: A 20% growth correlated with the 'Summer Sales Promotion.' The account currently averages a monthly growth rate of 3.5%, with notable engagement from promotional campaigns and interactive posts.\"\n\nYour goal is to offer insightful, data-driven answers that help optimize the social media account's strategy and performance."
              },
              "dataset": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "dataset",
                "display_name": "dataset",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "request": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "request",
                "display_name": "request",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "dataset",
                "request"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt"
        },
        "selected": true,
        "width": 320,
        "height": 432,
        "dragging": false
      },
      {
        "id": "ChatOutput-uW1RD",
        "type": "genericNode",
        "position": {
          "x": 2453.2304558892392,
          "y": 566.7941822475111
        },
        "data": {
          "id": "ChatOutput-uW1RD",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 2453.2304558892392,
          "y": 566.7941822475111
        },
        "dragging": false
      },
      {
        "id": "AstraDBToolComponent-Y1qYn",
        "type": "genericNode",
        "position": {
          "x": 862.7766632839996,
          "y": 537.5319221866728
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "api_endpoint": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_endpoint",
                "value": "https://781d144b-fe18-4482-8d34-8fd6ef6f15b8-us-east-2.apps.astra.datastax.com",
                "display_name": "API Endpoint",
                "advanced": false,
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom astrapy import Collection, DataAPIClient, Database\nfrom langchain.pydantic_v1 import BaseModel, Field, create_model\nfrom langchain_core.tools import StructuredTool\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.io import DictInput, IntInput, SecretStrInput, StrInput\nfrom langflow.schema import Data\n\n\nclass AstraDBToolComponent(LCToolComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Create a tool to get transactional data from DataStax Astra DB Collection\"\n    documentation: str = \"https://docs.langflow.org/Components/components-tools#astra-db-tool\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        StrInput(\n            name=\"tool_name\",\n            display_name=\"Tool Name\",\n            info=\"The name of the tool.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"tool_description\",\n            display_name=\"Tool Description\",\n            info=\"The description of the tool.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace Name\",\n            info=\"The name of the namespace within Astra where the collection is be stored.\",\n            value=\"default_keyspace\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        StrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"projection_attributes\",\n            display_name=\"Projection Attributes\",\n            info=\"Attributes to return separated by comma.\",\n            required=True,\n            value=\"*\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"tool_params\",\n            info=\"Attributes to filter and description to the model. Add ! for mandatory (e.g: !customerId)\",\n            display_name=\"Tool params\",\n            is_list=True,\n        ),\n        DictInput(\n            name=\"static_filters\",\n            info=\"Attributes to filter and correspoding value\",\n            display_name=\"Static filters\",\n            advanced=True,\n            is_list=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=5,\n        ),\n    ]\n\n    _cached_client: DataAPIClient | None = None\n    _cached_db: Database | None = None\n    _cached_collection: Collection | None = None\n\n    def _build_collection(self):\n        if self._cached_collection:\n            return self._cached_collection\n\n        _cached_client = DataAPIClient(self.token)\n        _cached_db = _cached_client.get_database(self.api_endpoint, namespace=self.namespace)\n        self._cached_collection = _cached_db.get_collection(self.collection_name)\n        return self._cached_collection\n\n    def create_args_schema(self) -> dict[str, BaseModel]:\n        args: dict[str, tuple[Any, Field] | list[str]] = {}\n\n        for key in self.tool_params:\n            if key.startswith(\"!\"):  # Mandatory\n                args[key[1:]] = (str, Field(description=self.tool_params[key]))\n            else:  # Optional\n                args[key] = (str | None, Field(description=self.tool_params[key], default=None))\n\n        model = create_model(\"ToolInput\", **args, __base__=BaseModel)\n        return {\"ToolInput\": model}\n\n    def build_tool(self) -> StructuredTool:\n        \"\"\"Builds an Astra DB Collection tool.\n\n        Returns:\n            Tool: The built Astra DB tool.\n        \"\"\"\n        schema_dict = self.create_args_schema()\n\n        tool = StructuredTool.from_function(\n            name=self.tool_name,\n            args_schema=schema_dict[\"ToolInput\"],\n            description=self.tool_description,\n            func=self.run_model,\n            return_direct=False,\n        )\n        self.status = \"Astra DB Tool created\"\n\n        return tool\n\n    def projection_args(self, input_str: str) -> dict:\n        elements = input_str.split(\",\")\n        result = {}\n\n        for element in elements:\n            if element.startswith(\"!\"):\n                result[element[1:]] = False\n            else:\n                result[element] = True\n\n        return result\n\n    def run_model(self, **args) -> Data | list[Data]:\n        collection = self._build_collection()\n        results = collection.find(\n            ({**args, **self.static_filters}),\n            projection=self.projection_args(self.projection_attributes),\n            limit=self.number_of_results,\n        )\n\n        data: list[Data] = [Data(data=doc) for doc in results]\n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "langflow",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "namespace": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "namespace",
                "value": "default_keyspace",
                "display_name": "Namespace Name",
                "advanced": true,
                "dynamic": false,
                "info": "The name of the namespace within Astra where the collection is be stored.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 5,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "projection_attributes": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "projection_attributes",
                "value": "*",
                "display_name": "Projection Attributes",
                "advanced": true,
                "dynamic": false,
                "info": "Attributes to return separated by comma.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "static_filters": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "static_filters",
                "value": {},
                "display_name": "Static filters",
                "advanced": true,
                "dynamic": false,
                "info": "Attributes to filter and correspoding value",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "token": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "token",
                "value": "ASTRA_DB_APPLICATION_TOKEN",
                "display_name": "Astra DB Application Token",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "tool_description": {
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_description",
                "value": "ASTRA_DB_APPLICATION_TOKEN",
                "display_name": "Tool Description",
                "advanced": false,
                "dynamic": false,
                "info": "The description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "tool_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_name",
                "value": "AstraCS:SGDZIUJEJvUcnRYNRrskFtpm:aaf32cf29761696f4c621fcc304d3f64419d4b1c476f5d8df2c42690d26844ed",
                "display_name": "Tool Name",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "tool_params": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_params",
                "value": {},
                "display_name": "Tool params",
                "advanced": false,
                "dynamic": false,
                "info": "Attributes to filter and description to the model. Add ! for mandatory (e.g: !customerId)",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              }
            },
            "description": "Create a tool to get transactional data from DataStax Astra DB Collection",
            "icon": "AstraDB",
            "base_classes": [
              "Data",
              "StructuredTool"
            ],
            "display_name": "Astra DB",
            "documentation": "https://docs.langflow.org/Components/components-tools#astra-db-tool",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "projection_attributes",
                  "token",
                  "tool_description",
                  "tool_name"
                ]
              },
              {
                "types": [
                  "StructuredTool"
                ],
                "selected": "StructuredTool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "projection_attributes",
                  "token",
                  "tool_description",
                  "tool_name"
                ]
              }
            ],
            "field_order": [
              "tool_name",
              "tool_description",
              "namespace",
              "collection_name",
              "token",
              "api_endpoint",
              "projection_attributes",
              "tool_params",
              "static_filters",
              "number_of_results"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "AstraDBToolComponent",
          "id": "AstraDBToolComponent-Y1qYn"
        },
        "selected": false,
        "width": 320,
        "height": 736,
        "dragging": false,
        "positionAbsolute": {
          "x": 862.7766632839996,
          "y": 537.5319221866728
        }
      },
      {
        "id": "ParseData-S7lum",
        "type": "genericNode",
        "position": {
          "x": 1309.6322626143422,
          "y": 569.3112824897677
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{data}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-S7lum"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "dragging": false
      },
      {
        "id": "GoogleGenerativeAIModel-04Trf",
        "type": "genericNode",
        "position": {
          "x": 2071.7737081460596,
          "y": 497.0456401396839
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pydantic.v1 import SecretStr\n\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "google_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "google_api_key",
                "value": "AIzaSyBkQLchPpgYuHVONGYBsif6DlVNRy5jXBg",
                "display_name": "Google API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_output_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_output_tokens",
                "value": "",
                "display_name": "Max Output Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gemini-1.5-pro",
                  "gemini-1.5-flash",
                  "gemini-1.5-flash-8b",
                  "gemini-1.0-pro",
                  "gemini-1.0-pro-vision",
                  "gemini-1.5-pro-001",
                  "gemini-1.5-pro-002",
                  "gemini-1.5-flash-001",
                  "gemini-1.5-flash-002",
                  "gemini-1.5-pro-exp-0827",
                  "gemini-1.5-flash-exp-0827",
                  "gemini-1.5-flash-8b-exp-0827",
                  "gemini-1.5-flash-8b-exp-0924",
                  "gemini-exp-1114"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "gemini-1.5-pro",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the model to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "top_k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_k",
                "value": "",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_p",
                "value": "",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Google Generative AI.",
            "icon": "GoogleGenerativeAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Google Generative AI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model",
              "google_api_key",
              "top_p",
              "temperature",
              "n",
              "top_k",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "GoogleGenerativeAIModel",
          "id": "GoogleGenerativeAIModel-04Trf"
        },
        "selected": false,
        "width": 320,
        "height": 757,
        "positionAbsolute": {
          "x": 2071.7737081460596,
          "y": 497.0456401396839
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatInput-jyJxK",
        "target": "Prompt-waFGY",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-jyJxKœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œrequestœ,œidœ:œPrompt-waFGYœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ChatInput-jyJxK{œdataTypeœ:œChatInputœ,œidœ:œChatInput-jyJxKœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-waFGY{œfieldNameœ:œrequestœ,œidœ:œPrompt-waFGYœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "request",
            "id": "Prompt-waFGY",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-jyJxK",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "ParseData-S7lum",
        "target": "Prompt-waFGY",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-S7lumœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œdatasetœ,œidœ:œPrompt-waFGYœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ParseData-S7lum{œdataTypeœ:œParseDataœ,œidœ:œParseData-S7lumœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-waFGY{œfieldNameœ:œdatasetœ,œidœ:œPrompt-waFGYœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset",
            "id": "Prompt-waFGY",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-S7lum",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-waFGY",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-waFGYœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-04Trf",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-04Trfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GoogleGenerativeAIModel-04Trf",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-waFGY",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-waFGY{œdataTypeœ:œPromptœ,œidœ:œPrompt-waFGYœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-04Trf{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-04Trfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "GoogleGenerativeAIModel-04Trf",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-04Trfœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-uW1RD",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-uW1RDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-uW1RD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-04Trf",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-04Trf{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-04Trfœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-uW1RD{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-uW1RDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "AstraDBToolComponent-Y1qYn",
        "sourceHandle": "{œdataTypeœ:œAstraDBToolComponentœ,œidœ:œAstraDBToolComponent-Y1qYnœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-S7lum",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-S7lumœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-S7lum",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AstraDBToolComponent",
            "id": "AstraDBToolComponent-Y1qYn",
            "name": "api_run_model",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-AstraDBToolComponent-Y1qYn{œdataTypeœ:œAstraDBToolComponentœ,œidœ:œAstraDBToolComponent-Y1qYnœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}-ParseData-S7lum{œfieldNameœ:œdataœ,œidœ:œParseData-S7lumœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": -481.8862434927519,
      "y": -268.3123640759828,
      "zoom": 0.5887701582587319
    }
  },
  "description": "Bridging Prompts for Brilliance.",
  "name": "Final Langflow ",
  "last_tested_version": "1.1.1",
  "endpoint_name": null,
  "is_component": false
}